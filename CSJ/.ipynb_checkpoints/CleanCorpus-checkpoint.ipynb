{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_chars = {\n",
    "\t\"ギャ\": \"gya\",\n",
    "\t\"ギュ\": \"gyu\" ,\n",
    "\t\"ギョ\": \"gyo\"  ,\n",
    "\t\"シャ\": \"Sa\" ,\n",
    "\t\"シュ\": \"Su\" ,\n",
    "\t\"ショ\": \"So\" ,\n",
    "\t\"ジャ\": \"dZa\" ,\n",
    "\t\"ジュ\": \"dZu\" ,\n",
    "\t\"ジョ\": \"dZo\" ,\n",
    "\t\"チャ\": \"tSa\" ,\n",
    "\t\"チュ\": \"tSu\" ,\n",
    "\t\"チョ\": \"tSo\" ,\n",
    "\t\"テュ\": \"tyu\",\n",
    "\t\"テャ\": \"tya\",\n",
    "\t\"テョ\": \"tyo\",\n",
    "\t\"ニャ\" : \"Ma\",\n",
    "\t\"ニィ\" : \"Mi\",\n",
    "\t\"ニュ\" : \"Mu\",\n",
    "\t\"ニェ\" : \"Me\",\n",
    "\t\"ニョ\" : \"Mo\",\n",
    "\t\"ヒャ\": \"ca\",\n",
    "\t\"ヒュ\": \"cu\",\n",
    "\t\"ヒョ\": \"co\",\n",
    "\t\"ビャ\": \"bya\",\n",
    "\t\"ビュ\": \"byu\",\n",
    "\t\"ビョ\": \"byo\",\n",
    "\t\"ピャ\": \"pya\",\n",
    "\t\"ピュ\": \"pyu\",\n",
    "\t\"ピョ\": \"pyo\",\n",
    "\t\"ミャ\": \"mya\",\n",
    "\t\"ミュ\": \"myu\",\n",
    "\t\"ミェ\": \"mye\",\n",
    "\t\"ミョ\": \"myo\",\n",
    "\t\"リャ\": \"rya\",\n",
    "\t\"リュ\": \"ryu\",\n",
    "\t\"リョ\": \"ryo\",\n",
    "\t\"キョ\": \"kyo\",\n",
    "\t\"キャ\": \"kya\",\n",
    "\t\"キュ\": \"kyu\",\n",
    "\t\"クヮ\": \"kwa\",\n",
    "\t\"グヮ\": \"gwa\",\n",
    "\t\"イェ\": \"ye\",\n",
    "\t\"ワ\": \"wa\",\n",
    "\t\"ウィ\": \"wi\",\n",
    "\t\"ウェ\": \"we\",\n",
    "\t\"ウォ\": \"wo\",\n",
    "\t\"シェ\": \"Se\",\n",
    "\t\"スィ\": \"si\",\n",
    "\t\"ジェ\": \"dZe\",\n",
    "\t\"ズィ\": \"zi\",\n",
    "\t\"ティ\": \"ti\",\n",
    "\t\"トゥ\": \"tu\",\n",
    "\t\"チェ\": \"tSe\",\n",
    "\t\"ツァ\": \"tsa\",\n",
    "\t\"ツィ\": \"tsi\",\n",
    "\t\"ツェ\": \"tse\",\n",
    "\t\"ツォ\": \"tso\",\n",
    "\t\"ディ\": \"di\",\n",
    "\t\"ドゥ\": \"du\",\n",
    "\t\"デュ\": \"dyu\",\n",
    "\t\"ヒェ\": \"hye\",\n",
    "\t\"ファ\": \"fa\",\n",
    "\t\"フィ\": \"fi\",\n",
    "\t\"フェ\": \"fe\",\n",
    "\t\"フォ\": \"fo\",\n",
    "\t\"フュ\": \"fyu\",\n",
    "\t\"ヴァ\": \"va\",\n",
    "\t\"ヴィ\": \"vi\",\n",
    "\t\"ヴェ\": \"ve\",\n",
    "\t\"ヴォ\": \"vo\"\n",
    "\t}\n",
    "\n",
    "sing_char = {\n",
    "\t\"ヴ\": \"vu\",\n",
    "\t\"ー\": \"H\",\n",
    "\t\"ン\": \"N\" ,\n",
    "\t\"ッ\": \"Q\",\n",
    "\t\"カ\": \"ka\",\n",
    "\t\"キ\": \"ki\",\n",
    "\t\"ク\": \"ku\",\n",
    "\t\"ケ\": \"ke\",\n",
    "\t\"コ\": \"ko\",\n",
    "\t\"ガ\": \"ga\",\n",
    "\t\"ギ\": \"gi\",\n",
    "\t\"グ\": \"gu\",\n",
    "\t\"ゲ\": \"ge\",\n",
    "\t\"ゴ\": \"go\",\n",
    "\t\"サ\": \"sa\",\n",
    "\t\"シ\": \"Si\",\n",
    "\t\"ス\": \"su\",\n",
    "\t\"セ\": \"se\",\n",
    "\t\"ソ\": \"so\",\n",
    "\t\"ザ\": \"za\",\n",
    "\t\"ジ\": \"dZi\",\n",
    "\t\"ズ\": \"zu\",\n",
    "\t\"ゼ\": \"ze\",\n",
    "\t\"ゾ\": \"zo\",\n",
    "\t\"タ\": \"ta\",\n",
    "\t\"チ\": \"tSi\",\n",
    "\t\"ツ\": \"tsu\",\n",
    "\t\"テ\": \"te\",\n",
    "\t\"ト\": \"to\",\n",
    "\t\"ダ\": \"da\",\n",
    "\t\"ヂ\": \"dZi\",\n",
    "\t\"デ\": \"de\",\n",
    "\t\"ド\": \"do\",\n",
    "\t\"ヅ\": \"dzu\",\n",
    "\t\"ナ\": \"na\",\n",
    "\t\"ニ\": \"Mi\",\n",
    "\t\"ヌ\": \"nu\",\n",
    "\t\"ネ\": \"ne\",\n",
    "\t\"ノ\": \"no\",\n",
    "\t\"ハ\": \"ha\",\n",
    "\t\"ヒ\": \"ci\",\n",
    "\t\"フ\": \"fu\",\n",
    "\t\"ヘ\": \"he\",\n",
    "\t\"ホ\": \"ho\",\n",
    "\t\"バ\": \"ba\",\n",
    "\t\"ビ\": \"bi\",\n",
    "\t\"ブ\": \"bu\",\n",
    "\t\"ベ\": \"be\",\n",
    "\t\"ボ\": \"bo\",\n",
    "\t\"パ\": \"pa\",\n",
    "\t\"ピ\": \"pi\",\n",
    "\t\"プ\": \"pu\",\n",
    "\t\"ペ\": \"pe\",\n",
    "\t\"ポ\": \"po\",\n",
    "\t\"マ\": \"ma\",\n",
    "\t\"ミ\": \"mi\",\n",
    "\t\"ム\": \"mu\",\n",
    "\t\"メ\": \"me\",\n",
    "\t\"モ\": \"mo\",\n",
    "\t\"ラ\": \"ra\",\n",
    "\t\"リ\": \"ri\",\n",
    "\t\"ル\": \"ru\",\n",
    "\t\"レ\": \"re\",\n",
    "\t\"ロ\": \"ro\",\n",
    "\t\"ア\": \"a\",\n",
    "\t\"イ\": \"i\",\n",
    "\t\"ウ\": \"u\",\n",
    "\t\"エ\": \"e\",\n",
    "\t\"オ\": \"o\",\n",
    "\t\"ヤ\": \"ya\",\n",
    "\t\"ユ\": \"yu\",\n",
    "\t\"ヨ\": \"yo\",\n",
    "\t\"ヲ\": \"wo\",\n",
    "    \"ワ\": \"wa\"\n",
    "    \n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function converts a katakana string into our phonetic notation\n",
    "def to_phonetic_slow(s):\n",
    "    s = re.sub(\"ー\", \"H\", s)\n",
    "    s = re.sub(\"ン\", \"N\" , s)\n",
    "    s = re.sub(\"ッ\", \"Q\", s)\n",
    "    s = re.sub(\"ギャ\", \"gya\", s)\n",
    "    s = re.sub(\"ギュ\", \"gyu\" , s)\n",
    "    s = re.sub(\"ギョ\", \"gyo\"  , s)\n",
    "    s = re.sub(\"シャ\", \"Sa\" , s)\n",
    "    s = re.sub(\"シュ\", \"Su\" , s)\n",
    "    s = re.sub(\"ショ\", \"So\" , s)\n",
    "    s = re.sub(\"ジャ\", \"dZa\" , s)\n",
    "    s = re.sub(\"ジュ\", \"dZu\" , s)\n",
    "    s = re.sub(\"ジョ\", \"dZo\" , s)\n",
    "    s = re.sub(\"チャ\", \"tSa\" , s) #cha\n",
    "    s = re.sub(\"チュ\", \"tSu\" , s)\n",
    "    s = re.sub(\"チョ\", \"tSo\" , s)\n",
    "    s = re.sub(\"テュ\", \"tyu\", s)\n",
    "    s = re.sub(\"テャ\", \"tya\", s)\n",
    "    s = re.sub(\"テョ\", \"tyo\", s)\n",
    "    s = re.sub(\"ニャ\" , \"Ma\", s) # M is the palatal nasal, (m is labial nasal)\n",
    "    s = re.sub(\"ニィ\" , \"Mi\", s)\n",
    "    s = re.sub(\"ニュ\" , \"Mu\", s)\n",
    "    s = re.sub(\"ニェ\" , \"Me\", s)\n",
    "    s = re.sub(\"ニョ\" , \"Mo\", s)\n",
    "    s = re.sub(\"ヒャ\", \"ca\", s) #hya\n",
    "    s = re.sub(\"ヒュ\", \"cu\", s) #hyu\n",
    "    s = re.sub(\"ヒョ\", \"co\", s) #hyo\n",
    "    s = re.sub(\"ビャ\", \"bya\", s)\n",
    "    s = re.sub(\"ビュ\", \"byu\", s)\n",
    "    s = re.sub(\"ビョ\", \"byo\", s)\n",
    "    s = re.sub(\"ピャ\", \"pya\", s)\n",
    "    s = re.sub(\"ピュ\", \"pyu\", s)\n",
    "    s = re.sub(\"ピョ\", \"pyo\", s)\n",
    "    s = re.sub(\"ミャ\", \"mya\", s)\n",
    "    s = re.sub(\"ミュ\", \"myu\", s)\n",
    "    s = re.sub(\"ミョ\", \"myo\", s)\n",
    "    s = re.sub(\"リャ\", \"rya\", s)\n",
    "    s = re.sub(\"リュ\", \"ryu\", s)\n",
    "    s = re.sub(\"リョ\", \"ryo\", s)\n",
    "    s = re.sub(\"キョ\", \"kyo\", s)\n",
    "    s = re.sub(\"キャ\", \"kya\", s)\n",
    "    s = re.sub(\"キュ\", \"kyu\", s)\n",
    "    s = re.sub(\"クヮ\", \"kwa\", s)\n",
    "    s = re.sub(\"グヮ\", \"gwa\", s)\n",
    "    s = re.sub(\"イェ\", \"ye\", s)\n",
    "    s = re.sub(\"ワ\", \"wa\", s)\n",
    "    s = re.sub(\"ウィ\", \"wi\", s)\n",
    "    s = re.sub(\"ウェ\", \"we\", s)\n",
    "    s = re.sub(\"ウォ\", \"wo\", s)\n",
    "    s = re.sub(\"シェ\", \"Se\", s)\n",
    "    s = re.sub(\"スィ\", \"si\", s)\n",
    "    s = re.sub(\"ジェ\", \"dZe\", s)\n",
    "    s = re.sub(\"ズィ\", \"zi\", s)\n",
    "    s = re.sub(\"ティ\", \"ti\", s)\n",
    "    s = re.sub(\"トゥ\", \"tu\", s)\n",
    "    s = re.sub(\"チェ\", \"tSe\", s)\n",
    "    s = re.sub(\"ツァ\", \"tsa\", s)\n",
    "    s = re.sub(\"ツィ\", \"tsi\", s)\n",
    "    s = re.sub(\"ツェ\", \"tse\", s)\n",
    "    s = re.sub(\"ツォ\", \"tso\", s)\n",
    "    s = re.sub(\"ディ\", \"di\", s)\n",
    "    s = re.sub(\"ドゥ\", \"du\", s)\n",
    "    s = re.sub(\"デュ\", \"dyu\", s)\n",
    "    s = re.sub(\"ヒェ\", \"hye\", s)\n",
    "    s = re.sub(\"ファ\", \"fa\", s)\n",
    "    s = re.sub(\"フィ\", \"fi\", s)\n",
    "    s = re.sub(\"フェ\", \"fe\", s)\n",
    "    s = re.sub(\"フォ\", \"fo\", s)\n",
    "    s = re.sub(\"フュ\", \"fyu\", s)\n",
    "    s = re.sub(\"ヴァ\", \"va\", s)\n",
    "    s = re.sub(\"ヴィ\", \"vi\", s)\n",
    "    s = re.sub(\"ヴェ\", \"ve\", s)\n",
    "    s = re.sub(\"ヴォ\", \"vo\", s)\n",
    "    s = re.sub(\"ヴ\", \"vu\", s)\n",
    "    s = re.sub(\"ミェ\", \"mye\", s)\n",
    "    s = re.sub(\"カ\", \"ka\", s)\n",
    "    s = re.sub(\"キ\", \"ki\", s)\n",
    "    s = re.sub(\"ク\", \"ku\", s)\n",
    "    s = re.sub(\"ケ\", \"ke\", s)\n",
    "    s = re.sub(\"コ\", \"ko\", s)\n",
    "    s = re.sub(\"ガ\", \"ga\", s)\n",
    "    s = re.sub(\"ギ\", \"gi\", s)\n",
    "    s = re.sub(\"グ\", \"gu\", s)\n",
    "    s = re.sub(\"ゲ\", \"ge\", s)\n",
    "    s = re.sub(\"ゴ\", \"go\", s)\n",
    "    s = re.sub(\"サ\", \"sa\", s)\n",
    "    s = re.sub(\"シ\", \"Si\", s)\n",
    "    s = re.sub(\"ス\", \"su\", s)\n",
    "    s = re.sub(\"セ\", \"se\", s)\n",
    "    s = re.sub(\"ソ\", \"so\", s)\n",
    "    s = re.sub(\"ザ\", \"za\", s)\n",
    "    s = re.sub(\"ジ\", \"dZi\", s) # marco\n",
    "    s = re.sub(\"ズ\", \"zu\", s) # marco\n",
    "    s = re.sub(\"ゼ\", \"ze\", s)\n",
    "    s = re.sub(\"ゾ\", \"zo\", s)\n",
    "    s = re.sub(\"タ\", \"ta\", s)\n",
    "    s = re.sub(\"チ\", \"tSi\", s)\n",
    "    s = re.sub(\"ツ\", \"tsu\", s)\n",
    "    s = re.sub(\"テ\", \"te\", s)\n",
    "    s = re.sub(\"ト\", \"to\", s)\n",
    "    s = re.sub(\"ダ\", \"da\", s)\n",
    "    s = re.sub(\"ヂ\", \"dZi\", s) # marco\n",
    "    s = re.sub(\"デ\", \"de\", s)\n",
    "    s = re.sub(\"ド\", \"do\", s)\n",
    "    s = re.sub(\"ヅ\", \"dzu\", s) # marco\n",
    "    s = re.sub(\"ナ\", \"na\", s)\n",
    "    s = re.sub(\"ニ\", \"Mi\", s) # palatalized\n",
    "    s = re.sub(\"ヌ\", \"nu\", s)\n",
    "    s = re.sub(\"ネ\", \"ne\", s)\n",
    "    s = re.sub(\"ノ\", \"no\", s)\n",
    "    s = re.sub(\"ハ\", \"ha\", s)\n",
    "    s = re.sub(\"ヒ\", \"ci\", s)\n",
    "    s = re.sub(\"フ\", \"fu\", s)\n",
    "    s = re.sub(\"ヘ\", \"he\", s)\n",
    "    s = re.sub(\"ホ\", \"ho\", s)\n",
    "    s = re.sub(\"バ\", \"ba\", s)\n",
    "    s = re.sub(\"ビ\", \"bi\", s)\n",
    "    s = re.sub(\"ブ\", \"bu\", s)\n",
    "    s = re.sub(\"ベ\", \"be\", s)\n",
    "    s = re.sub(\"ボ\", \"bo\", s)\n",
    "    s = re.sub(\"パ\", \"pa\", s)\n",
    "    s = re.sub(\"ピ\", \"pi\", s)\n",
    "    s = re.sub(\"プ\", \"pu\", s)\n",
    "    s = re.sub(\"ペ\", \"pe\", s)\n",
    "    s = re.sub(\"ポ\", \"po\", s)\n",
    "    s = re.sub(\"マ\", \"ma\", s)\n",
    "    s = re.sub(\"ミ\", \"mi\", s)\n",
    "    s = re.sub(\"ム\", \"mu\", s)\n",
    "    s = re.sub(\"メ\", \"me\", s)\n",
    "    s = re.sub(\"モ\", \"mo\", s)\n",
    "    s = re.sub(\"ラ\", \"ra\", s)\n",
    "    s = re.sub(\"リ\", \"ri\", s)\n",
    "    s = re.sub(\"ル\", \"ru\", s)\n",
    "    s = re.sub(\"レ\", \"re\", s)\n",
    "    s = re.sub(\"ロ\", \"ro\", s)\n",
    "    s = re.sub(\"ア\", \"a\", s)\n",
    "    s = re.sub(\"イ\", \"i\", s)\n",
    "    s = re.sub(\"ウ\", \"u\", s)\n",
    "    s = re.sub(\"エ\", \"e\", s)\n",
    "    s = re.sub(\"オ\", \"o\", s)\n",
    "    s = re.sub(\"ヤ\", \"ya\", s)\n",
    "    s = re.sub(\"ユ\", \"yu\", s)\n",
    "    s = re.sub(\"ヨ\", \"yo\", s)\n",
    "    s = re.sub(\"ヲ\", \"wo\", s)\n",
    "    \n",
    "    ## Apply phonological rules\n",
    "    \n",
    "    # gemination\n",
    "    \n",
    "    # replace every Q with the consonant that follows it. E.g. Qg --> gg, Qr --> rr, etc.\n",
    "    s = re.sub(\"Q([a-zA-Z])\", r'\\1\\1', s)\n",
    "    \n",
    "    \n",
    "    # vowel lengthing\n",
    "    s = re.sub(\"([aeiou])H\", r'\\1\\1', s)\n",
    "    \n",
    "    # nasal asimilation\n",
    "    \n",
    "    # rule 1a - remains as N (uvular nasal) before a pause\n",
    "    # no replacement needed for our code\n",
    "    \n",
    "    # rule 1b - labials\n",
    "    s = re.sub(\"Nm\", \"mm\", s)\n",
    "    s = re.sub(\"Np\", \"mb\", s)\n",
    "    s = re.sub(\"Nb\", \"mp\", s)\n",
    "    \n",
    "    # rule 1c - alveolars\n",
    "    s = re.sub(\"Nn\", \"nn\", s)\n",
    "    s = re.sub(\"Nt\", \"nt\", s)\n",
    "    s = re.sub(\"Nd\", \"nd\", s)\n",
    "    \n",
    "    # rule 1d - velars\n",
    "    s = re.sub(\"Nk\", \"Gk\", s)\n",
    "    s = re.sub(\"Ng\", \"Gg\", s)\n",
    "                  \n",
    "    # rule 1e - nasalized vowel before h, s, and z (whether palatalized or not)\n",
    "    # assume this is uvular nasal, leave this in place\n",
    "    \n",
    "    # rule 1f - before w, y, and vowels, nasalize the vowel\n",
    "    # assume this is uvular nasal, leave this in place\n",
    "    \n",
    "    # rule 1f - before w, y, and vowels, nasalize the vowel\n",
    "    # assume this is uvular nasal, leave this in place\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_phonetic(word):\n",
    "    index = 0\n",
    "    \n",
    "    roms = []\n",
    "    \n",
    "    \n",
    "    while index < len(word):\n",
    "        \n",
    "        #below is the same as \n",
    "        \n",
    "        #curr_kana = word[index:index+2]\n",
    "        #curr_roma = two_chars[curr_kana]\n",
    "        #roms.append(curr_roma)\n",
    "\n",
    "\n",
    "        if word[index:index + 2] in two_chars:\n",
    "            roms.append(two_chars[word[index:index + 2]])\n",
    "            index += 2\n",
    "        elif word[index:index + 1] in sing_char:\n",
    "            roms.append(sing_char[word[index:index + 1]])\n",
    "            index += 1\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Error in \\\"{}\\\": cannot convert \\\"{}\\\"\".format(word, word[index:index + 1]))\n",
    "            \n",
    "        \n",
    "            \n",
    "    s = \"\".join(roms)\n",
    "    \n",
    "    ## Apply phonological rules\n",
    "    \n",
    "    # gemination\n",
    "    \n",
    "    # replace every Q with the consonant that follows it. E.g. Qg --> gg, Qr --> rr, etc.\n",
    "    s = re.sub(\"Q([a-zA-Z])\", r'\\1\\1', s)\n",
    "    \n",
    "    \n",
    "    # vowel lengthing\n",
    "    s = re.sub(\"([aeiou])H\", r'\\1\\1', s)\n",
    "    \n",
    "    # nasal asimilation\n",
    "    \n",
    "    # rule 1a - remains as N (uvular nasal) before a pause\n",
    "    # no replacement needed for our code\n",
    "    \n",
    "    # rule 1b - labials\n",
    "    s = re.sub(\"Nm\", \"mm\", s)\n",
    "    s = re.sub(\"Np\", \"mb\", s)\n",
    "    s = re.sub(\"Nb\", \"mp\", s)\n",
    "    \n",
    "    # rule 1c - alveolars\n",
    "    s = re.sub(\"Nn\", \"nn\", s)\n",
    "    s = re.sub(\"Nt\", \"nt\", s)\n",
    "    s = re.sub(\"Nd\", \"nd\", s)\n",
    "    \n",
    "    # rule 1d - velars\n",
    "    s = re.sub(\"Nk\", \"Gk\", s)\n",
    "    s = re.sub(\"Ng\", \"Gg\", s)\n",
    "                  \n",
    "    # rule 1e - nasalized vowel before h, s, and z (whether palatalized or not)\n",
    "    # assume this is uvular nasal, leave this in place\n",
    "    \n",
    "    # rule 1f - before w, y, and vowels, nasalize the vowel\n",
    "    # assume this is uvular nasal, leave this in place\n",
    "    \n",
    "    # rule 1f - before w, y, and vowels, nasalize the vowel\n",
    "    # assume this is uvular nasal, leave this in place\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 100000 ***\n",
      "*** 200000 ***\n",
      "*** 300000 ***\n",
      "*** 400000 ***\n",
      "*** 500000 ***\n",
      "*** 600000 ***\n",
      "*** 700000 ***\n",
      "*** 800000 ***\n",
      "*** 900000 ***\n",
      "*** 1000000 ***\n",
      "*** 1100000 ***\n",
      "*** 1200000 ***\n",
      "*** 1300000 ***\n",
      "*** 1400000 ***\n",
      "*** 1500000 ***\n",
      "*** 1600000 ***\n",
      "*** 1700000 ***\n",
      "*** 1800000 ***\n",
      "*** 1900000 ***\n",
      "*** 2000000 ***\n",
      "*** 2100000 ***\n",
      "*** 2200000 ***\n",
      "*** 2300000 ***\n",
      "*** 2400000 ***\n",
      "*** 2500000 ***\n",
      "*** 2600000 ***\n",
      "*** 2700000 ***\n",
      "*** 2800000 ***\n",
      "*** 2900000 ***\n",
      "*** 3000000 ***\n",
      "*** 3100000 ***\n",
      "*** 3200000 ***\n",
      "*** 3300000 ***\n",
      "*** 3400000 ***\n",
      "*** 3500000 ***\n",
      "*** 3600000 ***\n",
      "*** 3700000 ***\n",
      "*** 3800000 ***\n",
      "*** 3900000 ***\n",
      "*** 4000000 ***\n",
      "*** 4100000 ***\n",
      "*** 4200000 ***\n",
      "*** 4300000 ***\n",
      "*** 4400000 ***\n",
      "*** 4500000 ***\n",
      "*** 4600000 ***\n",
      "*** 4700000 ***\n",
      "*** 4800000 ***\n",
      "*** 4900000 ***\n",
      "*** 5000000 ***\n",
      "*** 5100000 ***\n",
      "*** 5200000 ***\n",
      "*** 5300000 ***\n",
      "*** 5400000 ***\n",
      "*** 5500000 ***\n",
      "*** 5600000 ***\n",
      "*** 5700000 ***\n",
      "*** 5800000 ***\n",
      "*** 5900000 ***\n",
      "*** 6000000 ***\n",
      "*** 6100000 ***\n",
      "6198344\n",
      "92983\n"
     ]
    }
   ],
   "source": [
    "word_counter = 0\n",
    "\n",
    "bad_paren = 0\n",
    "\n",
    "counter = 1\n",
    "\n",
    "skip_chars = set(\"FD?OAKMLBX笑咳泣\")\n",
    "\n",
    "with open('words.csv', encoding=\"UTF-8\") as f:\n",
    "    \n",
    "    with open('clean.csv', 'w', encoding=\"UTF-8\") as outf:\n",
    "    \n",
    "        # write the header to the output file\n",
    "        outf.write(next(f))\n",
    "        \n",
    "        for line in f:\n",
    "\n",
    "            # remove all lines with annotations that indicate unusual pronunciation\n",
    "            # see the table in the paper for the CSJ corpus for the description of these flags\n",
    "\n",
    "            # remove lines with annotated commas\n",
    "            if line.count(\",\") != 5:\n",
    "                continue\n",
    "\n",
    "            # remove any lines with mismatched parentheses\n",
    "            if line.count(\"(\") != line.count(\")\"):\n",
    "                bad_paren += 1\n",
    "                continue\n",
    "\n",
    "            sid, pos, ortho, transcript, loan, sing = line[:-1].split(',')\n",
    "            \n",
    "            if \"<\" in line:\n",
    "                continue\n",
    "                \n",
    "            if \"×\" in line:\n",
    "                continue\n",
    "            \n",
    "            codes = []\n",
    "            \n",
    "            if \"(\" in line:\n",
    "            \n",
    "                paren_inds = [m.start() for m in re.finditer(\"\\(\", line)]\n",
    "                codes = [line[ind + 1] for ind in paren_inds]\n",
    "            \n",
    "            skip_line = False\n",
    "            \n",
    "            for code in codes:\n",
    "                if code in skip_chars:\n",
    "                    skip_line = True\n",
    "                    break\n",
    "                    \n",
    "            if skip_line:\n",
    "                continue\n",
    "                \n",
    "\n",
    "            word_counter += 1\n",
    "\n",
    "            # TODO, process the (W ;) ones\n",
    "            if \"(W\" in transcript:\n",
    "\n",
    "                pronounced_form = re.sub('\\(W ([^\\)]*);([^\\)]*)\\)', r'\\1', transcript)\n",
    "                phonological_form = re.sub('\\(W ([^\\)]*);([^\\)]*)\\)', r'\\2', transcript)\n",
    "                misp = \"M\" # flag that this word was mispronounced\n",
    "\n",
    "            else:\n",
    "                phonological_form = transcript\n",
    "                pronounced_form = transcript\n",
    "                misp = \"C\" # flag that this word was pronounced correctly\n",
    "\n",
    "            # determine the romanized forms of the words\n",
    "            rom_phon = to_phonetic(phonological_form)\n",
    "            rom_pron = to_phonetic(pronounced_form)\n",
    "\n",
    "            # pack the values to write to the file into an array\n",
    "            vals = list((sid, pos, ortho, phonological_form, pronounced_form, rom_phon, rom_pron, loan, sing, misp))\n",
    "\n",
    "            outf.write(','.join(vals) + '\\n')\n",
    "            \n",
    "            if counter % 100000 == 0:\n",
    "                print(\"*** {} ***\".format(counter))\n",
    "            \n",
    "            counter += 1\n",
    "        \n",
    "print(word_counter)\n",
    "print(bad_paren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to clean_000.csv\n",
      "Writing to clean_001.csv\n",
      "Writing to clean_002.csv\n",
      "Writing to clean_003.csv\n",
      "Writing to clean_004.csv\n",
      "Writing to clean_005.csv\n",
      "Writing to clean_006.csv\n",
      "Wrote all files\n"
     ]
    }
   ],
   "source": [
    "lines_per_file = 1000000\n",
    "\n",
    "file_counter = 0\n",
    "line_counter = 0\n",
    "\n",
    "\n",
    "with open('clean.csv', encoding=\"UTF-8\") as words_file:\n",
    "    header = next(words_file)\n",
    "    \n",
    "    out_file = None\n",
    "    \n",
    "    for line in words_file:\n",
    "        if line_counter % lines_per_file == 0:\n",
    "            if out_file is not None:\n",
    "                out_file.close()\n",
    "            currfname = \"clean_{}.csv\".format(str(1000 + file_counter)[1:])\n",
    "            print('Writing to', currfname)\n",
    "            out_file = open(currfname, 'w', encoding=\"UTF-8\")\n",
    "            out_file.write(header)\n",
    "            \n",
    "            file_counter += 1\n",
    "            \n",
    "        out_file.write(line)\n",
    "            \n",
    "        line_counter += 1\n",
    "        \n",
    "    if not out_file.closed:\n",
    "        out_file.close()\n",
    "        \n",
    "print('Wrote all files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
